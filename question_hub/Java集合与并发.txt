大概想法：并发源码、各种锁、线程安全

Q: 并发编程存在的问题？
A: 由于软硬件的资源限制，如网络、硬盘、CPU等，并发的代码可能仍在串行执行，这时程序不仅不会加快反而更慢，因为增加了上下文切换和资源调度的时间。

Q: 如何解决并发编程的问题？
A: 对于硬件资源限制，既然单机有上限，可以使用集群并行执行程序，通过负载均衡算法，让多个服务器处理数据。
    对于软件资源限制，可以考虑使用资源池进行复用。

Q: final域的内存语义，重排序规则
A: 1.在构造函数内对一个final域的写入，与随后把这个被构造对象的引用赋值给变量，这两个操作之间不能重排序。确保在对象引用为其他线程可见之前，
		对象的final域已经被正确初始化过了，而普通域不具有这个保障。
	2.在一个线程中，初次读对象引用与初次读该对象所包含的final域，JMM禁止处理器重排序这两个操作。编译器本就不会重排序这两个操作，因为它们有间接依赖关系。

Q: 内存屏障，缓存行
A: 内存屏障是一组处理器指令，用于实现对内存操作的顺序限制。
	缓存行是CPU高速缓存中可以分配的最小存储单位。CPU高速缓存是指L1、L2之类CPU内部缓存。
	
Q: 原子操作
A: 处理器自身能够保证从系统内存中读写一个字节是原子的。对同一个缓存行里进行操作也是原子的。但是跨总线宽度、跨多个缓存行等需要其他机制来保证复杂的原子性。
	总线锁：当一个处理器在总线上输出LOCK信号时，其他处理器的请求将被阻塞，该处理器可以独占共享内存。其他处理器也不能操作其他内存地址的数据。
	缓存锁定：频繁使用的内存会缓存到L1、L2之类的高速缓存中，并且被LOCK锁定，当回写到内存时，修改内部的内存地址，并允许缓存一致性机制，
		阻止同时修改由两个以上处理器缓存的内存数据。当数据跨多个缓存行时，不适用。

Q: CAS算法
A: Compare and Swap，比较并交换，如果当前值与旧值相同，则替换成新值。
	有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。
	使用Unsafe类的native方法compareAndSwap来做，会为CPU指令加上lock前缀，CAS同时具有volatile读和写的内存语义。
	是乐观锁。

Q: 指令重排序
A: 在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。共分3种：
		1.编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。
		2.指令级并行的重排序。现代处理器的并行技术。
		3.内存系统的重排序。由于处理器使用缓存和读写缓冲区，这使得加载和存储操作可能是乱序执行的。

	重排序可能导致多线程程序出现内存可见性问题。对于编译器重排序，JMM的编译器重排序规则会禁止特定类型的编译器重排序。对于处理器重排序，使用内存屏障来禁止。
	
Q: happens-before
A: 在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系。
	如果重排序之后的执行结果与原来一致，那么这种重排序是允许的。
	happens-before有许多规则，一个规则对应一个或多个编译器和处理器重排序规则。它避免了程序员去学习复杂的重排序规则以及具体实现。
	
Q: as-if-serial 语义
A: 不管怎么重排序，单线程程序的执行结果不能被改变。
	为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序。单线程中对控制依赖的操作重排序，不会改变执行结果，但是多线程会。

	as-if-serial是针对单线程程序，happens-before是针对正确同步的多线程程序，在不改变结果的前提下，尽可能地提高程序执行的并行度。

Q: volatile的介绍、应用和底层实现？
A: volatile是轻量级的synchronized，它保证了共享变量的可见性，确保能够被准确和一致地更新。即当一个线程修改一个共享变量时，另一个线程能读到这个修改的值。
		对volatile变量的读写具有原子性，但复合操作不具有原子性。
	具体实现是生成字节码时会在指令序列中插入内存屏障。转成汇编代码后，指令多了lock前缀。
	lock前缀作用有两个，一是会将当前处理器缓存行的数据写回到系统内存。执行期间会有总线锁或缓存锁定，阻止同时修改由两个以上处理器缓存的内存数据。
									  二是这个写回操作会使其他CPU里的缓存该内存地址的数据失效。如需用到该数据，重新从系统内存中读取。

	volatile内存语义：当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值刷新到主内存。
								 当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效，接下来将从主内存中读取共享变量。

Q: 双检锁中为什么instance使用volatile修饰
A: 为了防止重排序，初始化一个实例在字节码中有4步，1.申请内存空间，2.初始化默认值，3.执行构造方法，4.连接引用和实例。
	其中后两步可能会重排序，造成未完成构造的对象发布。使用volatile禁止指令重排序，避免这个问题。
	因为在volatile写操作之前任何操作都是不可重排序的。

Q: synchronized实现原理与应用
A: JVM基于进入和退出Monitor对象来实现方法同步和代码块同步。代码块同步是使用monitorenter和monitorexit指令实现的，方法同步依靠方法修饰符上的ACC_SYNCHRONIZED来完成。
	这两个指令实在编译后插入到同步代码块的开始位置和方法结束处或异常处，必须一一配对。
	任何对象都有一个monitor与之关联，当该monitor被持有后，它将处于锁定状态。线程执行到monitorenter指令时，就是尝试获取对象所对应的monitor所有权。
	
	synchronized用的锁存在Java对象头的Mark Word里。如果对象是数组类型，则对象头是3字宽，其他类型2字宽。在32位系统中，1字宽等于4字节。TODO

Q: 队列同步器AQS
A: 是用来构建锁或者其他同步组件的框架，它使用了一个int变量表示同步状态（资源数），通过内置的FIFO队列来完成资源获取线程的排队工作。
	大大降低了实现一个可靠的自定义同步组件的门槛（即自己实现一个锁）。

	独占式同步状态获取和释放的过程：在获取同步状态时，同步器维护一个同步队列，获取状态失败的线程会被加入到队列中并在队列中进行自旋。
			移出队列（或停止自旋）的条件是前驱节点为头节点且成功获取了同步状态。在释放同步状态后，唤醒头节点的后继节点。

	共享式获取与独占式获取最主要的区别在于同一时刻能否有多个线程同时获取到同步状态。例如读写锁，可以多个读，只能有一个写。

Q: AQS的非公平和公平锁如何实现的？AbstractQueuedSynchronizer
A: AQS使用一个整型的volatile变量state来维护同步状态
	内存语义，公平锁和非公平锁释放时，最后都要改变state值。
		公平锁获取时，会判断同步队列中当前节点是否有前驱节点。如果有，说明有其他线程更早地请求获取锁。没有再使用CAS获取锁。
		非公平锁获取时，直接使用CAS更新volatile。
		
	公平锁保证了锁的获取按照FIFO原则，代价是进行大量的线程切换。
	非公平锁由刚释放的线程重新获取到锁的可能性很大，减少了线程切换提升吞吐量，但是会造成其他线程长时间等待。

Q: 锁的内存语义
A: 当线程释放锁时，JMM会把线程对应的本地内存中的共享变量刷新到主内存中，
	当线程获取锁时，JMM会把线程对应的本地内存置为无效，从而使得必须从主内存中读取共享变量。
	线程A释放锁，线程B获得锁，实质上是线程A通过主内存向线程B发送消息。

Q: 乐观锁和悲观锁
A: 乐观锁：
		总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，
			可以使用版本号机制和CAS算法实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量。
	悲观锁：
		总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞。
			例如synchronized、ReentrantLock等独占锁。

Q: 偏向锁和轻量级锁
A: 为了减少获得锁和释放锁带来的性能消耗，引入了偏向锁和轻量级锁。锁一共有4中状态，无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态。
	这几个状态会随着竞争情况逐渐升级，但不能降级。只升不降是为了提供获得锁和释放锁的效率。
	
	当一个线程获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步代码块时不需要进行CAS操作来加锁和解锁，只需要简单地
		测试一下对象头的Mark Word里是否存储指向当前线程的偏向锁。如果测试成功，表示线程已经获得锁。如果测试失败，则测试偏向锁标识是否为1（表示当前是
		偏向锁）。如果不是偏向锁，则使用CAS竞争锁。如果是偏向锁，则尝试使用CAS将对象头的偏向锁指向当前线程。
	偏向锁使用了一种等待竞争出现才释放锁的机制。当有其他线程尝试竞争偏向锁时，会在全局安全点暂停拥有偏向锁的线程，检查其是否活着，如果不处于活动状态，
		则将对象头设置为无锁。如果线程活着 TODO偏向锁撤销流程
	
	轻量级锁是指线程在执行同步代码块前将对象头中的Mark Word复制到线程栈帧中的锁记录空间，然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的
		指针，如果成功则当前线程获得锁，如果失败则表示其他线程竞争锁，当前线程尝试自旋来获取锁，即不断地进行CAS修改，一段时间后仍失败，
		则锁膨胀为重量级锁，线程进入阻塞状态。
	解锁时使用CAS操作将锁记录空间的内容替换回对象头，如果成功则表示没有竞争发生，如果失败表示有竞争，轻量级锁已经膨胀成重量级锁。释放锁并唤醒等待的线程。

Q: 锁的优缺点对比和适用场景
A: 锁有4种状态，级别从低到高依次是无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态。
	偏向锁：如果同一个线程经常要获得某个锁，为了让它获得锁的代价更低而引入偏向锁。偏向锁使用了一种等到竞争出现才释放锁的机制，当其他线程尝试竞争偏向锁时，持有偏向锁的线程才释放锁。
			原理：当一个线程访问同步代码块时并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步代码块时不需要进行CAS操作来加锁和解锁。
			优点：加解锁不需要额外的消耗，和执行非同步方法相比仅存在纳秒级差距。
			缺点：如果线程间存在竞争，会带来额外的锁撤销的消耗。
			适用：只有一个线程访问同步代码块的场景。
	轻量级锁
			优点：竞争的线程不会阻塞，提高了程序的响应速度。
			缺点：自旋消耗CPU
			适用：追求响应时间，同步代码块执行速度非常快
	重量级锁
			优点：无自旋，不消耗CPU
			缺点：线程阻塞，响应时间变长
			适用：追求吞吐量，同步代码块执行速度慢

Q：sychronized和lock的区别      
A：Lock接口比同步代码块提供了更具扩展性的锁操作，允许更灵活的结构
		可以使锁更公平
		可以使线程在等待锁的时候响应中断
		可以让线程尝试获取锁，并在无法获取锁的时候立即返回或者等待一段时间
		可以在不同的范围，以不同的顺序获取和释放锁		

Q: 可重入锁有哪些？有什么作用？如何实现的可重入性？
A: ReentrantLock，重进入是指任意线程在获取到锁之后能够再次获取该锁而不会被锁阻塞。
	可重入锁最大的作用是避免死锁。
	增加了再次获取同步状态的处理逻辑：通过判断当前线程是否为获取锁的线程来决定获取操作是否成功，如果是则将同步状态值增加。释放锁减少同步状态值，只有彻底释放时才返回true

Q: 读写锁 ReentrantReadWriteLock
A: 维护了一对锁，一个读锁和一个写锁。通过分离读锁和写锁，使得并发性相比一般的排他锁有了很大的提升。
	在没有读写锁时，要实现这样的功能，需要用等待通知机制，当写开始时，其他操作进入等待，写完成后通知其他线程。写操作之间使用synchronized进行同步

Q：死锁的四个必要条件和如何处理死锁
A：死锁是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。
            这是一个严重的问题，因为死锁会让你的程序挂起无法完成任务，死锁的发生必须满足以下四个条件：
				互斥条件：一个资源每次只能被一个进程使用。
				请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
				不剥夺条件：进程已获得的资源，在末使用完之前，不能强行剥夺。
				循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。

	避免死锁最简单的方法就是阻止循环等待条件，将系统中所有的资源设置标志位、排序，规定所有的进程申请资源必须以一定的顺序（升序或降序）做操作来避免死锁。

Q：如何确保线程安全，线程同步的方法，
A：确保线程安全：同步synchronized、使用原子类、实现并发锁、使用volatile关键字、使用不变类和线程安全类。
     同步的方法：用锁！

Q: ConcurrentHashMap的原理（1.7）
A: HashMap在并发执行put操作时可能会引起死循环，因为多线程会导致HashMap的Entry链表形成环形数据结构，这样next节点永远不为空，产生死循环获取Entry.
	CHMap使用了分段锁，其中每个segment都是一个锁，segment中是HashEntry键值对数组。避免了竞争同一把锁。
	
	CHMap的get操作如何做到不加锁：它的get方法里将要使用的共享变量都定义成volatile类型，如用于统计segment大小的count和HashEntry的value。保证不会读到过期的值。
	
	CHMap的size操作是否加锁：要统计整个CHMap中元素的数量，就要统计所有segment中元素数量然后求和，为了高效，先尝试2次不锁segment方式统计各segment数量，
			如果统计过程中count发生了变化，则再加锁。判断是否发生变化是使用modCount变量，在put、remove、clean方法里都会使modCount加1，比较统计前后modCount即可。

Q: Condition的作用
A: 多线程间协调通信的工具类，实现等待/通知机制，功能与wait/notify类似，但是更强大。
	wait/notify只能在synchronized块内部使用
	condition可以创建不同的wait集合
	condition必须由lock创建，不能new产生
	一个lock可以绑定多个condition
	condition支持相应中断、定时功能

Q: 栈与队列，单向双向、阻塞非阻塞、有界无界、线程安不安全
A: 栈，   后进先出LIFO。
    队列，先进先出FIFO。
	Java虽然提供Stack类来实现栈结构，但是已不推荐使用，而是使用Deque双端队列。
	
	双端队列Deque接口的实现有
		非线程安全：
			LinkedList，   允许null
			ArrayDeque，不允许null
		线程安全：
			ConcurrentLinkedDeque，不允许null，不阻塞
			LinkedBlockingDeque，   不允许null，阻塞

	单向队列Queue
		有界：
			ArrayBlockingQueue，  必须指定长度，有界队列，阻塞，添加和删除使用同一个锁，生产者-消费者模式常用。
			LinkedBlockingQueue，默认长度Integer.MAX_VALUE，有界队列，阻塞，添加和删除两把锁是分开的，性能较好。
			SynchronousQueue ，   阻塞队列，内部容量为0，适合交换数据使用
		无界：put 操作永远都不会阻塞，空间限制来源于系统资源的限制，底层都使用CAS无锁编程
			ConcurrentLinkedQueue ， 线程安全非阻塞，通常具有较高吞吐量，但是具有读性能的不确定性，弱一致性。size()遍历队列，isEmpty()只检查头队列，性能差异大
			PriorityBlockingQueue ，	具有优先级的阻塞队列，put不会阻塞
			DelayQueue，						延时阻塞队列，适用场景：缓存、任务超市处理。
			LinkedTransferQueue ，		基于链表实现的无界阻塞队列，简单的说也是进行线程间数据交换的利器。预占模式。
		
		
		
	
