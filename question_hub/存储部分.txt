大概想法：MySQL、redis、hbase

Q: MySQL的事务隔离级别，有什么问题？丢失更新会发生在什么级别？
A: 读未提交 READ_UNCOMMITTED
	读已提交 READ_COMMITTED
	可重复读 REPEATABLE_READ
	序列化	  SERIALIZABLE
	
	更新丢失类似于不可重复读，因为事务A修改数据过程中，有可能事务B完成了修改，那么事务A提交会覆盖事务B的结果。
		使用隔离级别，设置为可重复读即可。
		使用排它锁，读取数据后不允许其他事务操作。
		使用乐观锁，给数据设置版本号等

Q: MyISAM 和 InnoDB 的区别？
A: 1、MyISAM：默认表类型，它是基于传统的ISAM类型，ISAM是Indexed Sequential Access Method (有索引的顺序访问方法) 的缩写，
			它是存储记录和文件的标准方法。不是事务安全的，而且不支持外键，只支持表锁。如果执行大量的select， MyISAM比较适合。
	2、InnoDB：支持事务安全的引擎，支持外键、行锁、事务是他的最大特点。如果有大量的update和insert，建议使用InnoDB，
			特别是针对多个并发和QPS较高的情况。

Q: MySQL的索引有哪些？区别是什么？
A: 按照索引值的唯一性，可分为唯一索引和非唯一索引。
	按照索引列的个数，可分为单列索引和复合索引。
	按照索引列的物理组织方式，
		B树索引：最常用。// TODO 具体实现
		位图索引：当字段的基数很低时，使用B树效率不高，例如性别只有男女两个值。应当使用位图索引。
		反向键索引：一种特殊的B树，构造相同，但是针对数值会将其翻转再进行索引。适用于自增类型的值。
		基于函数的索引：将要查询用到的表达式作为索引项。
		全局索引和局部索引

Q: MySQL的锁有哪些？意向锁是什么？
A: 大致分为两种锁：读锁（共享锁）和写锁（排它锁）。另外有意向共享锁、意向排它锁、间隙锁。
	意向锁均为表锁，当语句没有使用索引，innodb不能确定操作的行，这时就使用意向锁。
	
Q: 数据库死锁
A: 当两个事务都需要获得对方持有的排他锁才能完成事务，这样就导致了循环锁等待，也就是常见的死锁类型。
	解决死锁的方法：
		1、  数据库参数
		2、  应用中尽量约定程序读取表的顺序一样
		3、  应用中处理一个表时，尽量对处理的顺序排序
		4、  调整事务隔离级别（避免两个事务同时操作一行不存在的数据，容易发生死锁）
	
Q: MySQL表的扩容
A: 数据库很容易成为瓶颈，单机数据库的资源和处理能力有限，在高并发的分布式系统中，可采用分库分表突破单机局限。
	相关内容：
		读写分离: 不同的数据库，同步相同的数据，分别只负责数据的读和写；
		分区: 指定分区列表达式，把记录拆分到不同的区域中(必须是同一服务器，可以是不同硬盘)，应用看来还是同一张表，没有变化；
		分库：一个系统的多张数据表，存储到多个数据库实例中；
		分表: 对于一张多行多列的二维数据表，又分两种情形： 
			(1) 垂直分表: 竖向切分，不同分表存储不同的字段，可以把不常用或者大容量、或者不同业务的字段拆分出去； 
			(2) 水平分表: 横向切分，按照特定分片算法，不同分表存储不同的记录。
	
	分片策略：
		连续分片
			根据特定字段(比如用户ID、订单时间)的范围，值在该区间的，划分到特定节点。 
			优点：集群扩容后，指定新的范围落在新节点即可，无需进行数据迁移。 
			缺点：如果按时间划分，数据热点分布不均(历史数冷，当前数据热)，导致节点负荷不均。
		ID取模分片
			缺点：扩容后需要迁移数据。
		一致性Hash算法
			优点：扩容后只需迁移少量数据。
		Snowflake 分片
			优点：扩容后无需迁移数据。
			
	分库分表带来的问题：
		分布式事务
		跨节点join、连表、聚合等操作
		扩容后，新的分片规则导致迁移数据。

Q: 分库分表中间件
A: Sharding-jdbc，属于 client 层方案。优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能较高。缺点各系统耦合了该依赖。
	Mycat，属于 proxy 层方案。优点不耦合。缺点在于需要部署，维护一套中间件，运维成本高。
			
Q: 如何对单库单表的系统进行分库分表
A: 1. 停机迁移，停掉系统，导数据，再恢复系统。
	2. 双写迁移，CRUD操作同时对老库和新库进行，然后导数据，并对比较数据是否一致。

Q: 如何设计可以动态扩容缩容的分库分表方案？
A: 一开始就设计32个库，每个库32个表，总共是1024个表。
	先建立在一个数据库上的不同逻辑库，然后需要扩展的时候由DBA将逻辑库迁移到不同的服务器上，这是有一些便捷工具的，很方便。
	修改路由规则。

Q: 分库分表后，id主键如何处理？
A: 1. 数据库自增id，依靠单库单表生成自增id，拿到这个id后再去对应的业务表写入。
				缺点，单库有瓶颈，稍微改进可以是批量获取id
				适合场景，并发不高，但是数据量大
	2. 设置数据库 sequence 或者表自增字段步长。
				缺点，服务节点固定，步长也固定，如果要增加服务节点就很麻烦。
	3. UUID，本地生成，不需要基于数据库。
				缺点，太长，占用空间大，作为主键性能差，不具有有序性，会导致 B+ 树索引在写的时候有过多的随机写操作。
	4. 获取系统当前时间
				缺点，并发很高的时候，比如一秒并发几千，会有重复的情况。
				适合场景，将时间戳跟其他业务字段拼接作为id
	5. snowflake 算法
				twitter 开源的分布式 id 生成算法，把一个 64 位的 long 型的 id，1 个 bit 是不用的，
				用其中的 41 bit 作为毫秒数，用 10 bit 作为工作机器 id，12 bit 作为序列号。

Q: 如何实现MySQL读写分离
A: 基于主从复制架构，一个主库挂多个从库，只写主库，会自动把数据同步到从库上。

Q: MySQL主从复制原理
A: 主库将变更写入binlog日志，从库连接主库后，从库有个IO线程将主库的binlog日志拷贝到自己本地，写入一个relay中继日志中。
	接着从库中有一个SQL线程会从中继日志读取binlog，然后执行binlog中的内容，也就是本地执行一遍SQL，保证数据一致。
	
	问题：
		有延迟，刚写入主库的数据，在从库可能读不到。延迟可能高达几十毫秒。
		会丢失，主库突然宕机，数据还没同步到从库，那么从库上就没有这些数据。
		
	半同步复制，解决数据丢失的问题。也叫semi-sync复制，在主库写入binlog日志之后，会立刻强制将数据同步到从库，从库将日志写入本地relay log后，
		返回一个ack给主库，主库接收到至少一个从库的ack后才会认为写操作完成。
			
	并行复制，解决主从同步延时问题。从库开启多个线程，并行读取relay log中不同库的日志，然后并行重放不同库的日志，库级别的并行。

Q: MySQL主从同步延时问题
A: 分库，将一个主库拆成多个主库，每个主库的写并发减少几倍，此时主从延迟大大降低。
	并行复制，是库并行，但是如果某个库写入并发特别高，并行复制没有意义。
	代码重构，插入的数据立马查询可能查不到。如果必须得查，可以直连主库查询。
	
Q: 数据库锁释放时抛异常了，没有释放掉怎么办？
A: 加锁和解锁必须在一个数据库连接里

Q: 数据库在提交事务的时候突然断电，它是如何恢复的？
A: 数据库由两个文件组成，一个数据库文件和一个日志文件。通常情况下日志文件都要比数据库文件大很多，数据库进行任何写入操作的时候都是要先写日志。
	同样在执行事务的时候数据库首先记录下这个事务的redo操作日志，然后才开始真正操作数据库，在操作之前首先会把日志文件写入磁盘，那么当突然断电
	的时候，即使操作没有完成，在重启数据库的时候，会根据当前数据的情况进行undo回滚或者redo前滚，保证数据的强一致性。

Q: 数据库两阶段提交2PC(two - phase - commit)，一致性如何保证？
A: XA Transactions
	第一阶段：事务协调器要求每个涉及到事务的数据库预提交（precommit）此操作，并反映是否可以提交。
	第二阶段：事务协调器要求每个数据库提交数据。
	其中，如果有任何一个数据库否决此次提交，那么所有数据库都会被要求回滚它们在此事务中的那部分信息。
	
	可以在数据库分区之间获得一致性，根据CAP定理，那么一定会影响到可用性。在两阶段提交过程中，要求每个数据库都可用，假设单个数据库可用性为m，
	那么n个数据库整体的可用性就是m的n次方，n越大可用性就会越小

Q: 分布式事务的实现方案有哪些？如果让你自己设计，你应该怎么设计？
A: 两阶段提交（2PC）
		优点：尽量保证了数据的强一致，适合对数据强一致要求很高的关键领域。（也不能100%保证强一致）
		缺点：原理简单，牺牲了可用性，对性能影响较大，不适合高并发高性能场景。

	补偿事务（TCC）
		采用的补偿机制，核心思想是：针对每个操作，都要注册一个与其对应的确认和补偿撤销操作。分为三个阶段：
				1. try阶段主要是对业务系统做检测及资源预留。
				2. confirm阶段主要对业务系统做确认提交，try阶段执行成功并开始执行confirm阶段时，默认confirm阶段是不会出错的。要try成功，confirm一定成功。
				3. cancel阶段主要在业务执行错误，需要回滚的状态下执行的业务取消，预留资源释放。

		举例：假入 Bob 要向 Smith 转账，思路大概是：
					我们有一个本地方法，里面依次调用
					1、首先在 Try 阶段，要先调用远程接口把 Smith 和 Bob 的钱给冻结起来。
					2、在 Confirm 阶段，执行远程调用的转账的操作，转账成功进行解冻。
					3、如果第2步执行成功，那么转账成功，如果第二步执行失败，则调用远程冻结接口对应的解冻方法 (Cancel)。

		优点： 跟2PC比起来，实现以及流程相对简单了一些，但数据的一致性比2PC也要差一些
		缺点： 入侵业务，更复杂，在2,3步中都有可能失败。TCC属于应用层的一种补偿方式，所以需要程序员在实现的时候多写很多补偿的代码，在一些场景中，一些业务流程可能用TCC不太好定义及处理。
					如果出现网络连不通怎么办  //TODO

	本地消息表（异步确保）
		业界使用最多。核心思想是将分布式事务拆分成本地事务进行处理。
			消息生产方，需要额外建一个消息表，并记录消息发送状态。消息表和业务数据要在一个事务里提交，也就是说他们要在一个数据库里面。然后消息会经过MQ发送到消息的消费方。如果消息发送失败，会进行重试发送。
			消息消费方，需要处理这个消息，并完成自己的业务逻辑。此时如果本地事务处理成功，表明已经处理成功了，如果处理失败，那么就会重试执行。如果是业务上面的失败，可以给生产方发送一个业务补偿消息，通知生产方进行回滚等操作。
			生产方和消费方定时扫描本地消息表，把还没处理完成的消息或者失败的消息再发送一遍。如果有靠谱的自动对账补账逻辑，这种方案还是非常实用的。
		这种方案遵循BASE理论，采用的是最终一致性，笔者认为是这几种方案里面比较适合实际业务场景的，即不会出现像2PC那样复杂的实现(当调用链很长的时候，2PC的可用性是非常低的)，也不会像TCC那样可能出现确认或者回滚不了的情况。
		
		优点： 一种非常经典的实现，避免了分布式事务，实现了最终一致性。
		缺点： 消息表会耦合到业务系统中，如果没有封装好的解决方案，会有很多杂活需要处理。

	MQ 事务消息
		RocketMQ支持事务消息，采用的类似二阶段提交方式。但是RabbitMQ和Kafka都不支持。
		具体实现见中间件部分.txt
		
		优点： 实现了最终一致性，不需要依赖本地数据库事务。
		缺点： 实现难度大，主流MQ不支持，RocketMQ事务消息部分代码也未开源。
		
	Sagas 事务模型
		又叫做长时间运行的事务（Long-running-transaction）其核心思想就是拆分分布式系统中的长事务为多个短事务，或者叫多个本地事务，
		然后由 Sagas 工作流引擎负责协调，如果整个流程正常结束，那么就算是业务成功完成，如果在这过程中实现失败，
		那么Sagas工作流引擎就会以相反的顺序调用补偿操作，重新进行业务回滚。
		
		举例：购买旅游套餐业务操作分为三个宝座，预定车辆、预定宾馆、预定机票。从业务上讲他们属于同一个事务。
					假如预定机票失败了，那就要取消宾馆、取消车辆。
					
		这个理论比较新。
		
	你们公司是如何处理分布式事务的？
		特别严格的场景，用的是 TCC 来保证强一致性；然后其他的一些场景基于阿里的 RocketMQ 来实现分布式事务。
	
Q: Redis、Memcache、MongoDB的区别？
A: 都是NoSQL数据库。Redis、Memcache 比较相似，但与 MongoDB 完全不同，几乎没有可比性。
	Redis/Memcache 是基于内存的，讲究的是性能，多用作缓存层。
	MongoDB 是面向文档的，存储的是类似json的非结构化数据，查询方便，比较像关系型数据库。
	
	数据结构
		M：仅支持key-value类型。value最大只支持1MB
		R：支持k-v、list、set、zset、hash等。value最大支持512MB

	存储方式
		M：把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小 。通过LRU算法抛弃最少使用的数据。
		R：有部分存在硬盘上，支持数据的持久化！突破物理内存的限制。所有的key都在内存中，部分value会交换到磁盘。
		
	底层模型
		M：默认使用Slab Allocation机制管理内存，其主要思想是按照预先规定的大小，将分配的内存分割成特定长度的块以存储相应长度的key-value数据记录，以完全解决内存碎片问题。
		R：自己构建了VM机制，不调用系统函数
		
	分布式可拓展性
		M：在客户端应用中实现，即通过一致性哈希之类的算法指定目标数据的节点
		R：在服务端构建分布式存储，多节点，没有中心节点，各个节点地位一致，可伸缩。节点间通过二进制协议通信，与客户端通过ASCII协议通信。
				每个Master节点都会有对应的两个用于冗余的Slave节点。这样在整个集群中，任意两个节点的宕机都不会导致数据的不可用。
				当Master节点退出后，集群会自动选择一个Slave节点成为新的Master节点。
		
	性能
		M：多核，存储100K以上大数据性能较好。
		R：单核，存储小数据性能较好。可以在服务端直接对数据操作，减少网络IO。
		
	应用场景
		M：动态系统中减轻数据库负载，提升性能；做缓存，适合多读少写，大数据量的情况。
		R：适用于对读写效率要求都很高，数据处理业务复杂和对安全性要求较高的系统。

Q: Redis如果实现高并发和高可用，主从复制原理，哨兵原理
A: 高并发-主从架构
			一主多从，主负责写，并且将数据复制到其它的 slave 节点，从节点负责读。也可以很轻松实现水平扩容。
			redis 采用异步方式复制数据到 slave 节点。核心原理 TODO
			断点续传，master会在内存中维护一个 backlog，master 和 slave 都会保存一个 replica offset 还有一个 master run id，
					offset 就是保存在 backlog 中的。如果 master 和 slave 网络连接断掉了，slave 会让 master 从上次 replica offset 开始继续复制，
					如果没有找到对应的 offset，那么就会执行一次全量复制。
			过期 key 处理，slave 不会过期 key，只会等待 master 过期 key。如果 master 过期了一个 key，或者通过 LRU 淘汰了一个 key，
					那么会模拟一条 del 命令发送给 slave。
			master node 在故障时，自动检测，并且将某个 slave node 自动切换为 master node 

	高可用-故障转移，主备切换，哨兵
			集群监控：负责监控 redis master 和 slave 进程是否正常工作。
			消息通知：如果某个 redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。
			故障转移：如果 master node 挂掉了，会自动转移到 slave node 上。
			配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址。
			
			哨兵用于实现 redis 集群的高可用，本身也是分布式的，作为一个哨兵集群去运行，互相协同工作。
			故障转移时，判断一个 master node 是否宕机了，需要大部分的哨兵都同意才行，涉及到了分布式选举的问题。
			
			主备切换也可能导致数据丢失
					异步复制导致的数据丢失。
					脑裂导致的数据丢失。某个 master 所在机器突然脱离了正常的网络，跟其他 slave 机器不能连接，但是实际上 master 还运行着，客户端向其写入。

Q: Redis的集群模式 Redis cluster
A: 支持多个redis master node，每个 master node 都可以挂载多个 slave node。提供内置的高可用支持，部分 master 不可用时，还是可以继续工作。
	自动将数据进行分片，每个 master 上放一部分数据。
	TODO 还不够详细
	
	Redis cluster 功能强大，直接集成了 replication 和 sentinel 的功能
	
Q: Redis线程模型
A: Redis内部使用文件事件处理器（file event handler），它是单线程的，所以Redis才叫单线程模型。
	它采用 IO 多路复用机制同时监听多个 socket，将产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。
	文件事件处理器的结构包含 4 个部分：
			多个 socket
			IO 多路复用程序
			文件事件分派器
			事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）

	为什么效率高？
			纯内存操作。
			核心是基于非阻塞的 IO 多路复用机制。
			C 语言实现，一般来说，C 语言实现的程序“距离”操作系统更近，执行速度相对会更快。
			单线程反而避免了多线程的频繁上下文切换问题，预防了多线程可能产生的竞争问题。

Q: Redis过期策略
A: 定期删除
		默认是每隔 100ms 就随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除。
	惰性删除
		获取 key 的时候，如果此时 key 已经过期，就删除，不会返回任何东西。

	内存淘汰机制
		noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧，实在是太恶心了。
		allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）。
		allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个 key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的 key 给干掉啊。
		volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的 key（这个一般不太合适）。
		volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 key。
		volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 key 优先移除。

Q: Redis持久化方式有哪些？
A: RDB快照
		性能高。丢失的数据多。
		原理是将Reids在内存中的数据库记录定时dump到磁盘上的RDB持久化
		Redis支持将当前数据的快照存成一个数据文件的持久化机制，即RDB快照。但是一个持续写入的数据库如何生成快照呢？
		Redis借助了fork命令的copy on write机制。在生成快照时，将当前进程fork出一个子进程，然后在子进程中循环所有的数据，将数据写成为RDB文件。
		我们可以通过Redis的save指令来配置RDB快照生成的时机，比如配置10分钟就生成快照，也可以配置有1000次写入就生成快照，也可以多个规则一起实施。

		Redis的RDB文件不会马上换掉，因为其写操作是在一个新进程中进行的，当生成一个新的RDB文件时，Redis生成的子进程会先将数据写到一个临时文件中，
		然后通过原子性rename系统调用将临时文件重命名为RDB文件，这样在任何时候出现故障，Redis的RDB文件都总是可用的。
		同时，Redis的RDB文件也是Redis主从同步内部实现中的一环。RDB有他的不足，就是一旦数据库出现问题，
		那么我们的RDB文件中保存的数据并不是全新的，从上次RDB文件生成到Redis停机这段时间的数据全部丢掉了。

	AOF日志
		丢失少。日志文件比快照更大，性能降低。
		全称是append only file，它是一个追加写入的日志文件。类似于binlog，但不同的是，AOF文件是可识别的纯文本，它的内容就是一个个的Redis标准命令。
		只有那些会导致数据发生修改的命令才会追加到AOF文件。每一条修改数据的命令都生成一条日志，AOF文件会越来越大，所以Redis又提供了一个功能，
		叫做AOF rewrite。其功能就是重新生成一份AOF文件，新的AOF文件中一条记录的操作只会有一次，而不像一份老文件那样，可能记录了对同一个值的多次操作。
		其生成过程和RDB类似，也是fork一个进程，直接遍历数据，写入新的AOF临时文件。在写入新文件的过程中，所有的写操作日志还是会写到原来老的AOF文件中，
		同时还会记录在内存缓冲区中。当操作完成后，会将所有缓冲区中的日志一次性写入到临时文件中。然后调用原子性的rename命令用新的AOF文件取代老的AOF文件。

	redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择; 用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。

Q: redis服务不可用时，持久化方式有何影响？
A: RDB是定时记录内存快照，在持久化之前出现的宕机会导致没来得及写入磁盘的数据丢失。
	AOF可配置每秒同步、每次修改同步、不同步，如果配置的每秒同步，出现宕机那么这一秒修改的数据会丢失。

Q: redis负载均衡的实现？//TODO

Q: redis分布式锁，如果上锁失败怎么办？//TODO

Q: 缓存与数据库的双写一致性
A: 最常见的缓存模型，
		读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。
		更新的时候，先更新数据库，然后再删除缓存。

	为什么是删除缓存，而不是更新缓存？
		在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。可能需要计算。
		延迟加载的思想，只有在使用到的时候才加载缓存。
		
	先更新数据库，再删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致，怎么办？
		先删除缓存，再更新数据库。如果数据库更新失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致。
		因为读的时候缓存没有，所以去读了数据库中的旧数据，然后更新到缓存中。
		
	数据即将发生变更，先删除了缓存，然后要去修改数据库，此时还没修改。一个请求过来，去读缓存，发现缓存空了，去查询数据库，
	查到了旧数据，放到了缓存中。随后数据完成变更，这时缓存是旧的，数据库是新的。
		做数据的唯一标识，TODO

Q: 什么是 Redisson ？
A: Redisson是一个在Redis的基础上实现的Java驻内存数据网格（In-Memory Data Grid）。
	它不仅提供了一系列的分布式的Java常用对象，还实现了可重入锁（Reentrant Lock）、公平锁（Fair Lock、联锁（MultiLock）、 红锁（RedLock）、 
	读写锁（ReadWriteLock）等，还提供了许多分布式服务。Redisson提供了使用Redis的最简单和最便捷的方法。
	Redisson的宗旨是促进使用者对Redis的关注分离（Separation of Concern），从而让使用者能够将精力更集中地放在处理业务逻辑上。

Q: 缓存穿透
A: 查询一个一定不存在的数据，由于缓存是不命中时需要从数据库查询，查不到数据则不写入缓存，这将导致每次查询不存在的数据都会访问数据库。
	解决方案：
	1. 缓存空值。若查询返回的数据为空，直接缓存一个默认值（比如null），下次查询就有值了。注意，过期时间设置的要较短。
	2. 布隆过滤器。是一个很长的二进制向量和一系列随机映射函数。可以检索一个元素是否在一个集合中。优点是空间效率和查询时间都快，缺点是有一定的误识别率和删除困难。

Q: 缓存击穿
A: 某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库
	解决方案：
	1. 热点数据缓存永不过期。将过期时间设置在value中。
	2. 加互斥锁，去查数据库时需要先获得互斥锁，查询后设置缓存。要能根据key来加锁，获取A数据不影响其他线程获取B数据。

Q: 缓存雪崩
A: 缓存服务器挂掉，或者热点缓存失效，所有查询落在了数据库，造成了缓存雪崩。
	与缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，从而查数据库，对数据库造成巨大压力，可能也会挂掉。
	解决方案：
		事前，redis高可用、主从+哨兵、redis cluster、避免全盘崩溃。
		事中，本地ehcache缓存、hystrix对数据库限流，服务降级、避免mysql崩溃。
		事后，redis持久化，重启redis，从磁盘加载数据，恢复缓存。
	
Q: redis并发竞争问题
A: 利用redis自带的incr命令
	独占式锁，例如通过zk实现的，并判断时间戳或者版本号
	乐观锁，使用redis的命令watch实现
